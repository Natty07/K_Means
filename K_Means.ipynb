{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from numba import jit\n",
    "import operator\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance\n",
    "import collections\n",
    "from decimal import localcontext, Decimal, ROUND_HALF_UP\n",
    "from random import randrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data in he form of numpy.ndarray()\n",
    "def dataPreparation(DataFile):\n",
    "    DataSet = np.genfromtxt(DataFile, delimiter=',')\n",
    "    \n",
    "    return DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Euclidean distance\n",
    "def euclideanDistance(testInstance, tainingInstance):\n",
    "    distance = 0\n",
    "    distance = np.sqrt(np.sum(np.power(tainingInstance-testInstance, 2)))\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate minkowski distance\n",
    "def minkowskiDistance(testInstance, tainingInstance, p):\n",
    "    minkDistance = 0\n",
    "    minkDistance = distance.minkowski(testInstance,tainingInstance,p)\n",
    "    \n",
    "    return minkDistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate Hamming distance\n",
    "def hammingDistance(testInstance, tainingInstance):\n",
    "    hamDistance = 0\n",
    "    hamDistance = distance.hamming(tainingInstance,testInstance)\n",
    "    \n",
    "    return hamDistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get neighbours which takes the training set and each test value to calculate its neighbours\n",
    "def getNeighbors(trainingSet, testInstance, k):\n",
    "    distances = []\n",
    "    length = len(testInstance)\n",
    "    for y in range(len(trainingSet)):\n",
    "        '''For PART A,B,E,F'''\n",
    "        #dist = euclideanDistance(testInstance, trainingSet[y])\n",
    "        '''For PART D'''\n",
    "        dist = hammingDistance(testInstance, trainingSet[y])\n",
    "        distances.append((trainingSet[y], dist))\n",
    "    distances.sort(key=operator.itemgetter(1))\n",
    "    neighbors = []\n",
    "    for x in range(k):\n",
    "        neighbors.append(distances[x][0])\n",
    "    \n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get neighbours which takes the training set and each test value to calculate its neighbours\n",
    "def minkGetNeighbors(trainingSet, testInstance, k, p):\n",
    "    distances = []\n",
    "    length = len(testInstance)\n",
    "    for y in range(len(trainingSet)):\n",
    "        dist = minkowskiDistance(testInstance, trainingSet[y], p)\n",
    "        distances.append((trainingSet[y], dist))\n",
    "    distances.sort(key=operator.itemgetter(1))\n",
    "    neighbors = []\n",
    "    for x in range(k):\n",
    "        neighbors.append(distances[x][0])\n",
    "    \n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to rank the neighbours and find which is the closest and has high votes\n",
    "def getResponse(neighbors):\n",
    "    classVotes = {}\n",
    "    for x in range(len(neighbors)):\n",
    "        response = neighbors[x][0]\n",
    "        if response in classVotes:\n",
    "            classVotes[response] += 1\n",
    "        else:\n",
    "            classVotes[response] = 1\n",
    "    sortedVotes = sorted(classVotes.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    \n",
    "    return sortedVotes[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is to calculate the accuracy based on number of correct predictions\n",
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for x in range(len(testSet)):\n",
    "        print('testSet[x][0]',testSet[x][0])\n",
    "        print('predictions[x]',predictions[x])\n",
    "        if testSet[x][0] == predictions[x]:\n",
    "            correct += 1\n",
    "    \n",
    "    return (correct/float(len(testSet))) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is to calculate the accuracy based on number of correct predictions\n",
    "def b_getAccuracy(testVal, predictions):\n",
    "    correct = 0\n",
    "    if testVal == predictions:\n",
    "        #print('test point is: ',testVal)\n",
    "        #print('predicted is: ',predictions)\n",
    "        correct += 1\n",
    "    \n",
    "    return (correct * 100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST DATA\n",
    "def errorsForTestData(trainingSet,testSet,k_low,k_high):\n",
    "    errorsPlotTest = []\n",
    "    errorsTest = {'1':[],'2':[],'3':[],'4':[],'5':[],'6':[],'7':[],'8':[],'9':[],'10':[],\n",
    "                  '11':[],'12':[],'13':[],'14':[],'15':[],'16':[],'17':[],'18':[],'19':[],'20':[]}\n",
    "    startTime1 = datetime.datetime.now()\n",
    "    print('Start time for testSet is: ', startTime1)\n",
    "    for k in range (k_low,k_high):\n",
    "        #k = 3\n",
    "        predictions=[]\n",
    "        #print('TestSet Is: ',testSet)\n",
    "        for x in range(len(testSet)):\n",
    "            #print('TestSet[x] Is: ',testSet[x])\n",
    "            neighbors = getNeighbors(trainingSet, testSet[x], k)\n",
    "            #print('training set size is',len(trainingSet))\n",
    "            #print('testSet[x]=', testSet[x])\n",
    "            result = getResponse(neighbors)\n",
    "            predictions.append(result)\n",
    "            #print('> predicted=' + repr(result) + ', actual=' + repr(testSet[x][0]))\n",
    "            #print('testset(',str(x),') is ',datetime.datetime.now())\n",
    "        accuracy = getAccuracy(testSet, predictions)\n",
    "        testAcc = repr(accuracy)\n",
    "        print('Accuracy for test set of k = '+str(k)+' is: ' + testAcc + '%')\n",
    "        testAccFloat = float(testAcc)\n",
    "        error = 1-(testAccFloat/100)\n",
    "        kstr = str(k)\n",
    "        errorsTest[kstr].append(error)\n",
    "        errorsPlotTest.append(error)\n",
    "    endTime1 = datetime.datetime.now()\n",
    "    print('End time for testSet is: ', endTime1)\n",
    "    diffTime1 = endTime1 - startTime1\n",
    "    print('Time took is ', divmod(diffTime1.total_seconds(), 60))\n",
    "    \n",
    "    return errorsPlotTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING DATA\n",
    "def errorsForTrainingData(trainingSet,k_low,k_high):\n",
    "    errorsPlotTrain = []\n",
    "    errorsTrain = {'1':[],'2':[],'3':[],'4':[],'5':[],'6':[],'7':[],'8':[],'9':[],'10':[],\n",
    "                   '11':[],'12':[],'13':[],'14':[],'15':[],'16':[],'17':[],'18':[],'19':[],'20':[]}\n",
    "    startTime2 = datetime.datetime.now()\n",
    "    print('Start time for trainingSet is: ', startTime2)\n",
    "    for k in range (k_low,k_high):\n",
    "        #k = 3\n",
    "        predictions=[]\n",
    "        for x in range(len(trainingSet)):\n",
    "            neighbors = getNeighbors(trainingSet, trainingSet[x], k)\n",
    "            #print('training set size is',len(trainingSet))\n",
    "            #print('testSet[x]=', testSet[x])\n",
    "            result = getResponse(neighbors)\n",
    "            predictions.append(result)\n",
    "            #print('> predicted=' + repr(result) + ', actual=' + repr(testSet[x][0]))\n",
    "            #print('testset(',str(x),') is ',datetime.datetime.now())\n",
    "        accuracy = getAccuracy(trainingSet, predictions)\n",
    "        trainAcc = repr(accuracy)\n",
    "        print('Accuracy for training set of k = '+str(k)+' is: ' + trainAcc + '%')\n",
    "        tainAccFloat = float(trainAcc)\n",
    "        error = 1-(tainAccFloat/100)\n",
    "        kstr = str(k)\n",
    "        errorsTrain[kstr].append(error)\n",
    "        errorsPlotTrain.append(error)\n",
    "\n",
    "    endTime2 = datetime.datetime.now()\n",
    "    print('End time for trainingSet is ', endTime2)\n",
    "    diffTime2 = endTime2 - startTime2\n",
    "    print('Time took is ', divmod(diffTime2.total_seconds(), 60))\n",
    "    \n",
    "    return errorsPlotTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errorsForLOOCV(trainingSet,testSet,k):\n",
    "    errorsPlotTest = []\n",
    "    predictions=[]\n",
    "    #print('type of test set is: ',type(testSet))\n",
    "    #print('testSet is: ',testSet)\n",
    "    \n",
    "    #print('testSet[x] is',testSet[x])\n",
    "    neighbors = getNeighbors(trainingSet, testSet, k)\n",
    "    #print('training set size is',len(trainingSet))\n",
    "    #print('testSet[x]=', testSet[x])\n",
    "    result = getResponse(neighbors)\n",
    "    predictions = result\n",
    "    #print('predicted is: ',predictions)\n",
    "    #print('> predicted=' + repr(result) + ', actual=' + repr(testSet[x][0]))\n",
    "    #print('testset(',str(x),') is ',datetime.datetime.now())\n",
    "    \n",
    "    accuracy = b_getAccuracy(testSet[0], predictions)\n",
    "    testAcc = repr(accuracy)\n",
    "    #print('Accuracy for test set of k = '+str(k)+' is: ' + testAcc + '%')\n",
    "    testAccFloat = float(testAcc)\n",
    "    error = 1-(testAccFloat/100)\n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_errorsForLOOCV(trainingSet, testSet, k, p):\n",
    "    errorsPlotTest = []\n",
    "    predictions=[]\n",
    "    #print('type of test set is: ',type(testSet))\n",
    "    #print('testSet is: ',testSet)\n",
    "    \n",
    "    #print('testSet[x] is',testSet[x])\n",
    "    neighbors = minkGetNeighbors(trainingSet, testSet, k, p)\n",
    "    #print('training set size is',len(trainingSet))\n",
    "    #print('testSet[x]=', testSet[x])\n",
    "    result = getResponse(neighbors)\n",
    "    predictions = result\n",
    "    #print('predicted is: ',predictions)\n",
    "    #print('> predicted=' + repr(result) + ', actual=' + repr(testSet[x][0]))\n",
    "    #print('testset(',str(x),') is ',datetime.datetime.now())\n",
    "    \n",
    "    accuracy = b_getAccuracy(testSet[0], predictions)\n",
    "    testAcc = repr(accuracy)\n",
    "    #print('Accuracy for test set of k = '+str(k)+'and p = '+str(p)+' is: ' + testAcc + '%')\n",
    "    testAccFloat = float(testAcc)\n",
    "    error = 1-(testAccFloat/100)\n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random10percent(trainingSet):\n",
    "    # make a nested list, each list index is the label corresponded to the 'written' number\n",
    "    trainLabelsFull = [[] for _ in range(10)]\n",
    "    # go through the whole training set\n",
    "    for i in range(len(trainingSet)):\n",
    "        # get the label\n",
    "        val = int(trainingSet[i][0])\n",
    "        # add the trainingSet index of the label in the label's index-list\n",
    "        trainLabelsFull[val].append(i)\n",
    "        \n",
    "    # make a random training set list\n",
    "    trainSetRnd = []\n",
    "    # set a local context for rounding up halfs\n",
    "    with localcontext() as ctx:\n",
    "        ctx.rounding = ROUND_HALF_UP\n",
    "        # go through each label\n",
    "        for i in range(10):\n",
    "            # get the total amount of random elements; 10% of the total amount of label X in the training set\n",
    "            nmb = int((Decimal(len(trainLabelsFull[i])) / 10).to_integral_value())\n",
    "            # get y amount of indexes for label X in the training set\n",
    "            rndmArray = np.random.choice( trainLabelsFull[i], nmb )\n",
    "            # go through the randomly chosen indexes\n",
    "            for j in range(len(rndmArray)):\n",
    "                # extract the whole data point of the 'written' number from the training set\n",
    "                # and add it to the random training set lsit\n",
    "                trainSetRnd.append(trainingSet[rndmArray[j]])\n",
    "\n",
    "    # return the random training set list as a numpy array\n",
    "    \n",
    "    return np.asarray(trainSetRnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet = dataPreparation('MNIST_train_small.csv')\n",
    "testSet = dataPreparation('MNIST_test_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSetFull = dataPreparation('MNIST_train.csv')\n",
    "testSetFull = dataPreparation('MNIST_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = trainingSet[0][1:].reshape(28,28)\n",
    "#print(trainingSet_copy[2][1:])\n",
    "#print(image)\n",
    "plt.imshow(image, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PART A TRAINING DATA\n",
    "\n",
    "errorPlotTrainData = errorsForTrainingData(trainingSet,1,21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PART A TESTING DATA\n",
    "\n",
    "errorPlotTestData = errorsForTestData(trainingSet,testSet,1,21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PART B\n",
    "\n",
    "errorsLOOCV = {'1':[],'2':[],'3':[],'4':[],'5':[],'6':[],'7':[],'8':[],'9':[],'10':[],\n",
    "              '11':[],'12':[],'13':[],'14':[],'15':[],'16':[],'17':[],'18':[],'19':[],'20':[]}\n",
    "errorsPlot = []\n",
    "for k in range(1,21):\n",
    "    startTime = datetime.datetime.now()\n",
    "    print('Start time for k = ',str(k),' is: ',startTime)\n",
    "    error = 0\n",
    "    for l in range(len(trainingSet)):\n",
    "        #print('test point is: ',l)\n",
    "        test = trainingSet[l]\n",
    "        #print('data point is: ',test[0])\n",
    "        train = np.delete(trainingSet,l,axis=0)\n",
    "        error += errorsForLOOCV(train,test,k)\n",
    "    kStr = str(k)\n",
    "    errorAvg = error/len(trainingSet)\n",
    "    errorsLOOCV[kStr].append(errorAvg)\n",
    "    errorsPlot.append(errorAvg)\n",
    "    endTime = datetime.datetime.now()\n",
    "    print('End time for k = ',str(k),' is: ', endTime)\n",
    "    diffTime = endTime - startTime\n",
    "    print('Time took for k = ',str(k),' is: ', divmod(diffTime.total_seconds(), 60))\n",
    "    print('Error for LOOCV of k = '+str(k)+' is: ' +str(errorAvg))\n",
    "print(errorsLOOCV)\n",
    "print(errorsPlot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = ['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20']\n",
    "\n",
    "plt.xlabel('k',fontsize = 12)\n",
    "plt.ylabel('Error',fontsize = 12)\n",
    "plt.title('Small DataSet',fontsize = 12)\n",
    "plt.plot(k,errorPlotTrainData,'-o',label = 'Training Data Set (small)')\n",
    "plt.plot(k,errorPlotTestData,'-*',label = 'Testing Data Set (small)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "plt.xlabel('k',fontsize = 12)\n",
    "plt.ylabel('Error',fontsize = 12)\n",
    "plt.title('Small DataSet LOOCV',fontsize = 12)\n",
    "plt.plot(k,errorsPlot,'-o',label = 'LOOCV')\n",
    "plt.plot(k,errorForTest,'-*',label = 'TestData')\n",
    "plt.plot(k,errorForTrain,'-o',label = 'TrainData')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PART C\n",
    "\n",
    "errorsLOOCVp = {'1':[],'2':[],'3':[],'4':[],'5':[],'6':[],'7':[],'8':[],'9':[],'10':[],\n",
    "              '11':[],'12':[],'13':[],'14':[],'15':[],'16':[],'17':[],'18':[],'19':[],'20':[]}\n",
    "err = []\n",
    "for k in range(1,21):\n",
    "    errorsPlot = []\n",
    "    for p in range(1,16):\n",
    "        startTime = datetime.datetime.now()\n",
    "        print('Start time for k = ',str(k),' and p = ',str(p),' is: ',startTime)\n",
    "        error = 0\n",
    "        for l in range(len(trainingSet)):\n",
    "            #print('test point is: ',l)\n",
    "            test = trainingSet[l]\n",
    "            #print('data point is: ',test[0])\n",
    "            train = np.delete(trainingSet,l,axis=0)\n",
    "            error += c_errorsForLOOCV(train, test, k, p)\n",
    "        kStr = str(k)\n",
    "        pStr = str(p)\n",
    "        errorAvg = error/len(trainingSet)\n",
    "        errorsLOOCVp[kStr].append(errorAvg)\n",
    "        errorsPlot.append(errorAvg)\n",
    "        endTime = datetime.datetime.now()\n",
    "        print('End time for k = ',str(k),' and p = ',str(p),' is: ', endTime)\n",
    "        diffTime = endTime - startTime\n",
    "        print('Time took for k = ',str(k),' and p = ',str(p),' is: ', divmod(diffTime.total_seconds(), 60))\n",
    "        print('Error for LOOCV of k = '+str(k)+' and p = '+str(p)+' is: ' +str(errorAvg))\n",
    "    err.append(errorsPlot)\n",
    "print(errorsLOOCVp)\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PartD preparation\n",
    "\n",
    "trainingSet_copy = trainingSet\n",
    "for i in range(len(trainingSet_copy)):\n",
    "    for j in range(len(trainingSet_copy[i])):\n",
    "        if trainingSet_copy[i][j] > 1:\n",
    "            trainingSet_copy[i][j] = 1\n",
    "        else:\n",
    "            trainingSet_copy[i][j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PART D\n",
    "\n",
    "#Training and testing with training data\n",
    "errorPlotTrainData = errorsForTrainingData(trainingSet_copy,1,21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part D LOOCV\n",
    "\n",
    "errorsLOOCV_D = {'1':[],'2':[],'3':[],'4':[],'5':[],'6':[],'7':[],'8':[],'9':[],'10':[],\n",
    "              '11':[],'12':[],'13':[],'14':[],'15':[],'16':[],'17':[],'18':[],'19':[],'20':[]}\n",
    "errorsPlot_D = []\n",
    "for k in range(1,21):\n",
    "    startTime = datetime.datetime.now()\n",
    "    print('Start time for k = ',str(k),' is: ',startTime)\n",
    "    error_D = 0\n",
    "    for l in range(len(trainingSet_copy)):\n",
    "        #print('test point is: ',l)\n",
    "        test_D = trainingSet_copy[l]\n",
    "        #print('data point is: ',test[0])\n",
    "        train_D = np.delete(trainingSet_copy,l,axis=0)\n",
    "        error_D += errorsForLOOCV(train_D,test_D,k)\n",
    "    kStr = str(k)\n",
    "    errorAvg_D = error_D/len(trainingSet_copy)\n",
    "    errorsLOOCV_D[kStr].append(errorAvg_D)\n",
    "    errorsPlot_D.append(errorAvg_D)\n",
    "    endTime = datetime.datetime.now()\n",
    "    print('End time for k = ',str(k),' is: ', endTime)\n",
    "    diffTime = endTime - startTime\n",
    "    print('Time took for k = ',str(k),' is: ', divmod(diffTime.total_seconds(), 60))\n",
    "    print('Error for LOOCV of k = '+str(k)+' is: ' +str(errorAvg_D))\n",
    "print(errorsLOOCV_D)\n",
    "print(errorsPlot_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data for randomization\n",
    "\n",
    "trainingRnd = random10percent(trainingSetFull)\n",
    "testingRnd = random10percent(testSetFull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Claculate the frequency of each class\n",
    "\n",
    "print('Length of training set Full is: ',len(trainingSetFull))\n",
    "trainLabelsFull = []\n",
    "for i in range(len(trainingSetFull)):\n",
    "    trainLabelsFull.append(trainingSetFull[i][0])\n",
    "#print(trainLabels)\n",
    "ctr = collections.Counter(trainLabelsFull)\n",
    "print('TRAINING SET FULL: ',ctr)\n",
    "\n",
    "print('Length of training set Sampled is: ',len(testingRnd))\n",
    "print(len(trainingRnd))\n",
    "trainLabelsRnd = []\n",
    "for i in range(len(trainingRnd)):\n",
    "    trainLabelsRnd.append(trainingRnd[i][0])\n",
    "#print(trainLabels)\n",
    "ctr = collections.Counter(trainLabelsRnd)\n",
    "print('TRAINING SET SAMPLED: ',ctr)\n",
    "\n",
    "print('Length of test set Full is: ',len(testSetFull))\n",
    "testLabelsFull = []\n",
    "for i in range(len(testSetFull)):\n",
    "    testLabelsFull.append(testSetFull[i][0])\n",
    "#print(trainLabels)\n",
    "ctr = collections.Counter(testLabelsFull)\n",
    "print('TEST SET FULL: ',ctr)\n",
    "\n",
    "print('Length of test set Sampled is: ',len(testingRnd))\n",
    "testLabelsRnd = []\n",
    "for i in range(len(testingRnd)):\n",
    "    testLabelsRnd.append(testingRnd[i][0])\n",
    "#print(trainLabels)\n",
    "ctr = collections.Counter(testLabelsRnd)\n",
    "print('TEST SET SAMPLED: ',ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART E (10% from all class)\n",
    "errorsLOOCVp = {'1':[],'2':[],'3':[],'4':[],'5':[],'6':[],'7':[],'8':[],'9':[],'10':[],\n",
    "              '11':[],'12':[],'13':[],'14':[],'15':[],'16':[],'17':[],'18':[],'19':[],'20':[]}\n",
    "err = []\n",
    "errorsPlot = []\n",
    "for k in range(1,21):\n",
    "    startTime = datetime.datetime.now()\n",
    "    print('Start time for k = ', str(k),' is: ', startTime)\n",
    "    error = 0\n",
    "    #print('length is ', len(trainingRnd))\n",
    "    for l in range(len(trainingRnd)):\n",
    "        #print('test point is: ',l)\n",
    "        test = trainingRnd[l]\n",
    "        #print('data point is: ',test[0])\n",
    "        train = np.delete(trainingRnd,l,axis=0)\n",
    "        error += errorsForLOOCV(train, test, k)\n",
    "        #print('test point is: ', l, ' data point is: ', test[0])\n",
    "    kStr = str(k)\n",
    "    errorAvg = error/len(trainingRnd)\n",
    "    errorsLOOCVp[kStr].append(errorAvg)\n",
    "    errorsPlot.append(errorAvg)\n",
    "    endTime = datetime.datetime.now()\n",
    "    print('End time for k = ', str(k),' is: ', endTime)\n",
    "    diffTime = endTime - startTime\n",
    "    print('Time took for k = ', str(k),' is: ', divmod(diffTime.total_seconds(), 60))\n",
    "    print('Error for LOOCV of k = ', str(k), ' is: ', str(errorAvg))\n",
    "print(errorsLOOCVp)\n",
    "print(errorsPlot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PART F (Full set testing)\n",
    "errorPlotTestData = errorsForTestData(trainingRnd,testSetFull,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(errorPlotTrainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PART G\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainingRnd.shape)\n",
    "pcaTrain = trainingRnd[:,1:]\n",
    "pcaTrainLabels = trainingRnd[:,[0]]\n",
    "print(pcaTrain.shape)\n",
    "print(pcaTrainLabels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# Make an instance of the Model\n",
    "pca = PCA(.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(pcaTrain)\n",
    "pcaTrainNew = scaler.transform(pcaTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(pcaTrainNew)\n",
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcaTrainNew = pca.transform(pcaTrainNew)\n",
    "print(pcaTrainNew.shape)\n",
    "pcaTrainFinal = np.concatenate((pcaTrainLabels,pcaTrainNew),axis=1)\n",
    "print(pcaTrainFinal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorsLOOCV_G = {'1':[],'2':[],'3':[],'4':[],'5':[],'6':[],'7':[],'8':[],'9':[],'10':[],\n",
    "              '11':[],'12':[],'13':[],'14':[],'15':[],'16':[],'17':[],'18':[],'19':[],'20':[]}\n",
    "errorsPlot_G = []\n",
    "for k in range(2,6):\n",
    "    startTime = datetime.datetime.now()\n",
    "    print('Start time for k = ',str(k),' is: ',startTime)\n",
    "    error_G = 0\n",
    "    for l in range(len(pcaTrainFinal)):\n",
    "        #print('test point is: ',l)\n",
    "        test_G = pcaTrainFinal[l]\n",
    "        #print('data point is: ',test[0])\n",
    "        train_G = np.delete(pcaTrainFinal,l,axis=0)\n",
    "        error_G += errorsForLOOCV(train_G,test_G,k)\n",
    "    kStr = str(k)\n",
    "    errorAvg_G = error_G/len(pcaTrainFinal)\n",
    "    errorsLOOCV_G[kStr].append(errorAvg_G)\n",
    "    errorsPlot_G.append(errorAvg_G)\n",
    "    endTime = datetime.datetime.now()\n",
    "    print('End time for k = ',str(k),' is: ', endTime)\n",
    "    diffTime = endTime - startTime\n",
    "    print('Time took for k = ',str(k),' is: ', divmod(diffTime.total_seconds(), 60))\n",
    "    print('Error for LOOCV of k = '+str(k)+' is: ' +str(errorAvg_G))\n",
    "print(errorsLOOCV_G)\n",
    "print(errorsPlot_G)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
